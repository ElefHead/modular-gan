{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "\n",
    "import PIL \n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from gan.networks import Generator, Discriminator, GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"..\") / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ganesh/workspace/python/GAN/data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_labels), (_, _) = keras.datasets.mnist.load_data(path=(data_path / \"mnist.npz\").resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_image.reshape(train_image.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(labels, output):\n",
    "    return keras.losses.BinaryCrossentropy(from_logits=True)(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(dlosses, glosses):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.plot(dlosses, label=\"Discriminative Loss\")\n",
    "    ax.plot(glosses, label=\"Generative Loss\")\n",
    "    ax.set_xlabel(\"Batch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.6338 - g_loss: 0.8871\n",
      "Epoch 2/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.6408 - g_loss: 0.8886\n",
      "Epoch 3/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.6145 - g_loss: 0.9614\n",
      "Epoch 4/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.6044 - g_loss: 1.0121\n",
      "Epoch 5/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5995 - g_loss: 1.0350\n",
      "Epoch 6/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5944 - g_loss: 1.0579\n",
      "Epoch 7/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5884 - g_loss: 1.0827\n",
      "Epoch 8/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5817 - g_loss: 1.1088\n",
      "Epoch 9/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5765 - g_loss: 1.1260\n",
      "Epoch 10/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5714 - g_loss: 1.1537\n",
      "Epoch 11/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5661 - g_loss: 1.1748\n",
      "Epoch 12/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5622 - g_loss: 1.1853\n",
      "Epoch 13/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5589 - g_loss: 1.2098\n",
      "Epoch 14/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5571 - g_loss: 1.2270\n",
      "Epoch 15/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5540 - g_loss: 1.2351\n",
      "Epoch 16/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5523 - g_loss: 1.2435\n",
      "Epoch 17/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5511 - g_loss: 1.2544\n",
      "Epoch 18/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5482 - g_loss: 1.2666\n",
      "Epoch 19/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5496 - g_loss: 1.2748\n",
      "Epoch 20/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5463 - g_loss: 1.2796\n",
      "Epoch 21/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5479 - g_loss: 1.2831\n",
      "Epoch 22/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5476 - g_loss: 1.2864\n",
      "Epoch 23/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5454 - g_loss: 1.2817\n",
      "Epoch 24/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5475 - g_loss: 1.2893\n",
      "Epoch 25/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5474 - g_loss: 1.2878\n",
      "Epoch 26/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5465 - g_loss: 1.2897\n",
      "Epoch 27/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5440 - g_loss: 1.2932\n",
      "Epoch 28/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5453 - g_loss: 1.2997\n",
      "Epoch 29/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5478 - g_loss: 1.2944\n",
      "Epoch 30/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5457 - g_loss: 1.3001\n",
      "Epoch 31/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5441 - g_loss: 1.3038\n",
      "Epoch 32/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5430 - g_loss: 1.3022\n",
      "Epoch 33/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5453 - g_loss: 1.3042\n",
      "Epoch 34/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5426 - g_loss: 1.3148\n",
      "Epoch 35/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5415 - g_loss: 1.3146\n",
      "Epoch 36/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5412 - g_loss: 1.3130\n",
      "Epoch 37/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5426 - g_loss: 1.3161\n",
      "Epoch 38/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5421 - g_loss: 1.3067\n",
      "Epoch 39/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5392 - g_loss: 1.3178\n",
      "Epoch 40/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5425 - g_loss: 1.3198\n",
      "Epoch 41/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5409 - g_loss: 1.3238\n",
      "Epoch 42/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5392 - g_loss: 1.3253\n",
      "Epoch 43/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5396 - g_loss: 1.3280\n",
      "Epoch 44/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5415 - g_loss: 1.3296\n",
      "Epoch 45/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5359 - g_loss: 1.3360\n",
      "Epoch 46/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5381 - g_loss: 1.3406\n",
      "Epoch 47/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5362 - g_loss: 1.3371\n",
      "Epoch 48/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5376 - g_loss: 1.3440\n",
      "Epoch 49/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5363 - g_loss: 1.3401\n",
      "Epoch 50/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5359 - g_loss: 1.3491\n",
      "Epoch 51/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5392 - g_loss: 1.3513\n",
      "Epoch 52/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5372 - g_loss: 1.3412\n",
      "Epoch 53/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5396 - g_loss: 1.3453\n",
      "Epoch 54/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5363 - g_loss: 1.3530\n",
      "Epoch 55/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5380 - g_loss: 1.3475\n",
      "Epoch 56/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5378 - g_loss: 1.3554\n",
      "Epoch 57/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5366 - g_loss: 1.3503\n",
      "Epoch 58/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5357 - g_loss: 1.3553\n",
      "Epoch 59/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5365 - g_loss: 1.3498\n",
      "Epoch 60/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5337 - g_loss: 1.3526\n",
      "Epoch 61/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5383 - g_loss: 1.3480\n",
      "Epoch 62/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5337 - g_loss: 1.3513\n",
      "Epoch 63/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5342 - g_loss: 1.3543\n",
      "Epoch 64/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5370 - g_loss: 1.3613\n",
      "Epoch 65/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5399 - g_loss: 1.3541\n",
      "Epoch 66/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5365 - g_loss: 1.3493\n",
      "Epoch 67/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5379 - g_loss: 1.3615\n",
      "Epoch 68/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5368 - g_loss: 1.3509\n",
      "Epoch 69/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5393 - g_loss: 1.3581\n",
      "Epoch 70/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5382 - g_loss: 1.3564\n",
      "Epoch 71/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5371 - g_loss: 1.3544\n",
      "Epoch 72/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5387 - g_loss: 1.3468\n",
      "Epoch 73/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5378 - g_loss: 1.3525\n",
      "Epoch 74/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5394 - g_loss: 1.3494\n",
      "Epoch 75/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5397 - g_loss: 1.3488\n",
      "Epoch 76/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5401 - g_loss: 1.3472\n",
      "Epoch 77/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5400 - g_loss: 1.3484\n",
      "Epoch 78/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5399 - g_loss: 1.3455\n",
      "Epoch 79/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5400 - g_loss: 1.3482\n",
      "Epoch 80/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5395 - g_loss: 1.3550\n",
      "Epoch 81/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5402 - g_loss: 1.3537\n",
      "Epoch 82/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5426 - g_loss: 1.3447\n",
      "Epoch 83/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5407 - g_loss: 1.3479\n",
      "Epoch 84/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5409 - g_loss: 1.3465\n",
      "Epoch 85/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5421 - g_loss: 1.3510\n",
      "Epoch 86/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5419 - g_loss: 1.3464\n",
      "Epoch 87/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5433 - g_loss: 1.3427\n",
      "Epoch 88/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5421 - g_loss: 1.3448\n",
      "Epoch 89/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5442 - g_loss: 1.3364\n",
      "Epoch 90/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5423 - g_loss: 1.3497\n",
      "Epoch 91/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5426 - g_loss: 1.3437\n",
      "Epoch 92/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5421 - g_loss: 1.3432\n",
      "Epoch 93/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5403 - g_loss: 1.3548\n",
      "Epoch 94/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5433 - g_loss: 1.3489\n",
      "Epoch 95/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5418 - g_loss: 1.3502\n",
      "Epoch 96/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5414 - g_loss: 1.3516\n",
      "Epoch 97/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5421 - g_loss: 1.3568\n",
      "Epoch 98/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5443 - g_loss: 1.3469\n",
      "Epoch 99/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5412 - g_loss: 1.3511\n",
      "Epoch 100/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5435 - g_loss: 1.3505\n",
      "Epoch 101/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5423 - g_loss: 1.3493\n",
      "Epoch 102/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5417 - g_loss: 1.3541\n",
      "Epoch 103/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5436 - g_loss: 1.3493\n",
      "Epoch 104/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5428 - g_loss: 1.3483\n",
      "Epoch 105/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5429 - g_loss: 1.3500\n",
      "Epoch 106/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5424 - g_loss: 1.3509\n",
      "Epoch 107/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5417 - g_loss: 1.3537\n",
      "Epoch 108/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5412 - g_loss: 1.3469\n",
      "Epoch 109/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5413 - g_loss: 1.3491\n",
      "Epoch 110/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5408 - g_loss: 1.3535\n",
      "Epoch 111/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5420 - g_loss: 1.3535\n",
      "Epoch 112/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5409 - g_loss: 1.3552\n",
      "Epoch 113/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5435 - g_loss: 1.3498\n",
      "Epoch 114/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5446 - g_loss: 1.3518\n",
      "Epoch 115/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5438 - g_loss: 1.3611\n",
      "Epoch 116/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5458 - g_loss: 1.3520\n",
      "Epoch 117/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5424 - g_loss: 1.3626\n",
      "Epoch 118/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5445 - g_loss: 1.3582\n",
      "Epoch 119/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5444 - g_loss: 1.3573\n",
      "Epoch 120/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5433 - g_loss: 1.3586\n",
      "Epoch 121/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5464 - g_loss: 1.3582\n",
      "Epoch 122/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5418 - g_loss: 1.3574\n",
      "Epoch 123/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5446 - g_loss: 1.3623\n",
      "Epoch 124/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5475 - g_loss: 1.3593\n",
      "Epoch 125/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5433 - g_loss: 1.3538\n",
      "Epoch 126/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5457 - g_loss: 1.3643\n",
      "Epoch 127/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5424 - g_loss: 1.3622\n",
      "Epoch 128/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5434 - g_loss: 1.3619\n",
      "Epoch 129/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5444 - g_loss: 1.3611\n",
      "Epoch 130/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5398 - g_loss: 1.3620\n",
      "Epoch 131/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5421 - g_loss: 1.3657\n",
      "Epoch 132/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5412 - g_loss: 1.3686\n",
      "Epoch 133/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5427 - g_loss: 1.3614\n",
      "Epoch 134/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5415 - g_loss: 1.3612\n",
      "Epoch 135/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5430 - g_loss: 1.3684\n",
      "Epoch 136/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5420 - g_loss: 1.3657\n",
      "Epoch 137/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5414 - g_loss: 1.3692\n",
      "Epoch 138/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5420 - g_loss: 1.3694\n",
      "Epoch 139/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5444 - g_loss: 1.3671\n",
      "Epoch 140/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5415 - g_loss: 1.3734\n",
      "Epoch 141/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5398 - g_loss: 1.3739\n",
      "Epoch 142/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5413 - g_loss: 1.3668\n",
      "Epoch 143/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5429 - g_loss: 1.3739\n",
      "Epoch 144/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5458 - g_loss: 1.3663\n",
      "Epoch 145/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5411 - g_loss: 1.3749\n",
      "Epoch 146/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5407 - g_loss: 1.3649\n",
      "Epoch 147/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5415 - g_loss: 1.3682\n",
      "Epoch 148/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5439 - g_loss: 1.3696\n",
      "Epoch 149/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5429 - g_loss: 1.3720\n",
      "Epoch 150/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5416 - g_loss: 1.3702\n",
      "Epoch 151/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5395 - g_loss: 1.3696\n",
      "Epoch 152/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5418 - g_loss: 1.3720\n",
      "Epoch 153/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5411 - g_loss: 1.3714\n",
      "Epoch 154/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5414 - g_loss: 1.3795\n",
      "Epoch 155/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5414 - g_loss: 1.3757\n",
      "Epoch 156/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5421 - g_loss: 1.3794\n",
      "Epoch 157/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5428 - g_loss: 1.3737\n",
      "Epoch 158/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5384 - g_loss: 1.3843\n",
      "Epoch 159/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5380 - g_loss: 1.3869\n",
      "Epoch 160/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5379 - g_loss: 1.3888\n",
      "Epoch 161/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5380 - g_loss: 1.3885\n",
      "Epoch 162/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5380 - g_loss: 1.3871\n",
      "Epoch 163/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5372 - g_loss: 1.3851\n",
      "Epoch 164/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5399 - g_loss: 1.3922\n",
      "Epoch 165/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5383 - g_loss: 1.3864\n",
      "Epoch 166/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5402 - g_loss: 1.3964\n",
      "Epoch 167/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5365 - g_loss: 1.3952\n",
      "Epoch 168/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5370 - g_loss: 1.3885\n",
      "Epoch 169/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5376 - g_loss: 1.3952\n",
      "Epoch 170/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5355 - g_loss: 1.3812\n",
      "Epoch 171/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5379 - g_loss: 1.4033\n",
      "Epoch 172/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5384 - g_loss: 1.3985\n",
      "Epoch 173/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5353 - g_loss: 1.3938\n",
      "Epoch 174/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5345 - g_loss: 1.3960\n",
      "Epoch 175/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5370 - g_loss: 1.3976\n",
      "Epoch 176/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5343 - g_loss: 1.3976\n",
      "Epoch 177/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5343 - g_loss: 1.3978\n",
      "Epoch 178/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5343 - g_loss: 1.4006\n",
      "Epoch 179/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5364 - g_loss: 1.3970\n",
      "Epoch 180/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5344 - g_loss: 1.4081\n",
      "Epoch 181/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5350 - g_loss: 1.4094\n",
      "Epoch 182/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5338 - g_loss: 1.4072\n",
      "Epoch 183/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5319 - g_loss: 1.4134\n",
      "Epoch 184/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5354 - g_loss: 1.4114\n",
      "Epoch 185/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5324 - g_loss: 1.4004\n",
      "Epoch 186/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5346 - g_loss: 1.4140\n",
      "Epoch 187/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5364 - g_loss: 1.4128\n",
      "Epoch 188/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5327 - g_loss: 1.4066\n",
      "Epoch 189/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5336 - g_loss: 1.4145\n",
      "Epoch 190/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5327 - g_loss: 1.4069\n",
      "Epoch 191/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5366 - g_loss: 1.4129\n",
      "Epoch 192/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5322 - g_loss: 1.4082\n",
      "Epoch 193/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5324 - g_loss: 1.4227\n",
      "Epoch 194/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5331 - g_loss: 1.4173\n",
      "Epoch 195/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5335 - g_loss: 1.4142\n",
      "Epoch 196/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5331 - g_loss: 1.4149\n",
      "Epoch 197/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5322 - g_loss: 1.4191\n",
      "Epoch 198/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5319 - g_loss: 1.4184\n",
      "Epoch 199/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5313 - g_loss: 1.4265\n",
      "Epoch 200/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5322 - g_loss: 1.4209\n",
      "Epoch 201/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5294 - g_loss: 1.4191\n",
      "Epoch 202/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5301 - g_loss: 1.4228\n",
      "Epoch 203/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5301 - g_loss: 1.4306\n",
      "Epoch 204/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5273 - g_loss: 1.4268\n",
      "Epoch 205/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5329 - g_loss: 1.4275\n",
      "Epoch 206/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5301 - g_loss: 1.4337\n",
      "Epoch 207/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5286 - g_loss: 1.4335\n",
      "Epoch 208/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5290 - g_loss: 1.4355\n",
      "Epoch 209/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5310 - g_loss: 1.4297\n",
      "Epoch 210/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5295 - g_loss: 1.4331\n",
      "Epoch 211/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5261 - g_loss: 1.4457\n",
      "Epoch 212/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5289 - g_loss: 1.4419\n",
      "Epoch 213/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5285 - g_loss: 1.4325\n",
      "Epoch 214/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5294 - g_loss: 1.4386\n",
      "Epoch 215/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5270 - g_loss: 1.4504\n",
      "Epoch 216/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5275 - g_loss: 1.4462\n",
      "Epoch 217/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5297 - g_loss: 1.4488\n",
      "Epoch 218/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5259 - g_loss: 1.4373\n",
      "Epoch 219/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5263 - g_loss: 1.4421\n",
      "Epoch 220/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5262 - g_loss: 1.4552\n",
      "Epoch 221/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5264 - g_loss: 1.4461\n",
      "Epoch 222/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5287 - g_loss: 1.4387\n",
      "Epoch 223/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5264 - g_loss: 1.4495\n",
      "Epoch 224/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5271 - g_loss: 1.4498\n",
      "Epoch 225/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5247 - g_loss: 1.4519\n",
      "Epoch 226/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5259 - g_loss: 1.4619\n",
      "Epoch 227/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5275 - g_loss: 1.4535\n",
      "Epoch 228/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5279 - g_loss: 1.4595\n",
      "Epoch 229/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5235 - g_loss: 1.4547\n",
      "Epoch 230/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5278 - g_loss: 1.4499\n",
      "Epoch 231/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5267 - g_loss: 1.4567\n",
      "Epoch 232/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5254 - g_loss: 1.4554\n",
      "Epoch 233/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5240 - g_loss: 1.4611\n",
      "Epoch 234/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5234 - g_loss: 1.4664\n",
      "Epoch 235/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5264 - g_loss: 1.4597\n",
      "Epoch 236/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5246 - g_loss: 1.4646\n",
      "Epoch 237/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5233 - g_loss: 1.4722\n",
      "Epoch 238/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5248 - g_loss: 1.4624\n",
      "Epoch 239/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5232 - g_loss: 1.4688\n",
      "Epoch 240/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5246 - g_loss: 1.4670\n",
      "Epoch 241/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5223 - g_loss: 1.4624\n",
      "Epoch 242/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5273 - g_loss: 1.4731\n",
      "Epoch 243/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5196 - g_loss: 1.4713\n",
      "Epoch 244/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5235 - g_loss: 1.4778\n",
      "Epoch 245/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5210 - g_loss: 1.4721\n",
      "Epoch 246/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5250 - g_loss: 1.4686\n",
      "Epoch 247/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5215 - g_loss: 1.4722\n",
      "Epoch 248/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5272 - g_loss: 1.4811\n",
      "Epoch 249/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5187 - g_loss: 1.4796\n",
      "Epoch 250/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5218 - g_loss: 1.4800\n",
      "Epoch 251/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5218 - g_loss: 1.4827\n",
      "Epoch 252/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5231 - g_loss: 1.4694\n",
      "Epoch 253/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5214 - g_loss: 1.4756\n",
      "Epoch 254/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5206 - g_loss: 1.4767\n",
      "Epoch 255/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5200 - g_loss: 1.4877\n",
      "Epoch 256/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5221 - g_loss: 1.4790\n",
      "Epoch 257/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5191 - g_loss: 1.4805\n",
      "Epoch 258/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5189 - g_loss: 1.4904\n",
      "Epoch 259/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5200 - g_loss: 1.4921\n",
      "Epoch 260/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5196 - g_loss: 1.4845\n",
      "Epoch 261/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5187 - g_loss: 1.4949\n",
      "Epoch 262/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5205 - g_loss: 1.4929\n",
      "Epoch 263/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5183 - g_loss: 1.4984\n",
      "Epoch 264/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5207 - g_loss: 1.4955\n",
      "Epoch 265/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5184 - g_loss: 1.5042\n",
      "Epoch 266/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5186 - g_loss: 1.5002\n",
      "Epoch 267/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5175 - g_loss: 1.4963\n",
      "Epoch 268/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5180 - g_loss: 1.5033\n",
      "Epoch 269/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5188 - g_loss: 1.4921\n",
      "Epoch 270/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5139 - g_loss: 1.4945\n",
      "Epoch 271/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5184 - g_loss: 1.5063\n",
      "Epoch 272/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5136 - g_loss: 1.5022\n",
      "Epoch 273/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5192 - g_loss: 1.5051\n",
      "Epoch 274/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5154 - g_loss: 1.4999\n",
      "Epoch 275/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5180 - g_loss: 1.5140\n",
      "Epoch 276/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5137 - g_loss: 1.5130\n",
      "Epoch 277/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5116 - g_loss: 1.5131\n",
      "Epoch 278/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5152 - g_loss: 1.5147\n",
      "Epoch 279/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5113 - g_loss: 1.5088\n",
      "Epoch 280/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5129 - g_loss: 1.5222\n",
      "Epoch 281/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5141 - g_loss: 1.5271\n",
      "Epoch 282/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5141 - g_loss: 1.5213\n",
      "Epoch 283/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5144 - g_loss: 1.5180\n",
      "Epoch 284/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5161 - g_loss: 1.5369\n",
      "Epoch 285/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5123 - g_loss: 1.5162\n",
      "Epoch 286/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5147 - g_loss: 1.5297\n",
      "Epoch 287/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5120 - g_loss: 1.5323\n",
      "Epoch 288/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5152 - g_loss: 1.5308\n",
      "Epoch 289/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5116 - g_loss: 1.5203\n",
      "Epoch 290/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5130 - g_loss: 1.5341\n",
      "Epoch 291/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5126 - g_loss: 1.5290\n",
      "Epoch 292/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5132 - g_loss: 1.5390\n",
      "Epoch 293/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5147 - g_loss: 1.5324\n",
      "Epoch 294/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5113 - g_loss: 1.5416\n",
      "Epoch 295/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5121 - g_loss: 1.5319\n",
      "Epoch 296/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5123 - g_loss: 1.5356\n",
      "Epoch 297/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5089 - g_loss: 1.5417\n",
      "Epoch 298/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5109 - g_loss: 1.5429\n",
      "Epoch 299/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5117 - g_loss: 1.5397\n",
      "Epoch 300/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5097 - g_loss: 1.5361\n",
      "Epoch 301/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5106 - g_loss: 1.5403\n",
      "Epoch 302/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5110 - g_loss: 1.5361\n",
      "Epoch 303/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5109 - g_loss: 1.5471\n",
      "Epoch 304/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5102 - g_loss: 1.5387\n",
      "Epoch 305/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5104 - g_loss: 1.5518\n",
      "Epoch 306/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5071 - g_loss: 1.5497\n",
      "Epoch 307/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5086 - g_loss: 1.5579\n",
      "Epoch 308/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5072 - g_loss: 1.5557\n",
      "Epoch 309/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5092 - g_loss: 1.5521\n",
      "Epoch 310/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5096 - g_loss: 1.5557\n",
      "Epoch 311/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5053 - g_loss: 1.5578\n",
      "Epoch 312/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5058 - g_loss: 1.5596\n",
      "Epoch 313/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5074 - g_loss: 1.5526\n",
      "Epoch 314/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5053 - g_loss: 1.5581\n",
      "Epoch 315/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5075 - g_loss: 1.5639\n",
      "Epoch 316/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5067 - g_loss: 1.5651\n",
      "Epoch 317/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5048 - g_loss: 1.5719\n",
      "Epoch 318/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5048 - g_loss: 1.5716\n",
      "Epoch 319/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5078 - g_loss: 1.5655\n",
      "Epoch 320/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5057 - g_loss: 1.5756\n",
      "Epoch 321/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5077 - g_loss: 1.5734\n",
      "Epoch 322/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5052 - g_loss: 1.5744\n",
      "Epoch 323/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5051 - g_loss: 1.5725\n",
      "Epoch 324/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5079 - g_loss: 1.5693\n",
      "Epoch 325/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5031 - g_loss: 1.5691\n",
      "Epoch 326/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5061 - g_loss: 1.5830\n",
      "Epoch 327/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5022 - g_loss: 1.5794\n",
      "Epoch 328/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5006 - g_loss: 1.5811\n",
      "Epoch 329/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5041 - g_loss: 1.5819\n",
      "Epoch 330/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5034 - g_loss: 1.5870\n",
      "Epoch 331/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5032 - g_loss: 1.5822\n",
      "Epoch 332/450\n",
      "1875/1875 [==============================] - 14s 8ms/step - d_loss: 0.5031 - g_loss: 1.5895\n",
      "Epoch 333/450\n",
      "1730/1875 [==========================>...] - ETA: 1s - d_loss: 0.5033 - g_loss: 1.5984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4978 - g_loss: 1.6045\n",
      "Epoch 342/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5007 - g_loss: 1.6039\n",
      "Epoch 343/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4989 - g_loss: 1.6061\n",
      "Epoch 344/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4999 - g_loss: 1.6159\n",
      "Epoch 345/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4980 - g_loss: 1.6052\n",
      "Epoch 346/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4974 - g_loss: 1.6053\n",
      "Epoch 347/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4969 - g_loss: 1.6145\n",
      "Epoch 348/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.5020 - g_loss: 1.6135\n",
      "Epoch 349/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4971 - g_loss: 1.6155\n",
      "Epoch 350/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4972 - g_loss: 1.6289\n",
      "Epoch 351/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4975 - g_loss: 1.6185\n",
      "Epoch 352/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4991 - g_loss: 1.6159\n",
      "Epoch 353/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4987 - g_loss: 1.6125\n",
      "Epoch 354/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4960 - g_loss: 1.6147\n",
      "Epoch 355/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4968 - g_loss: 1.6195\n",
      "Epoch 356/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4986 - g_loss: 1.6140\n",
      "Epoch 357/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4983 - g_loss: 1.6258\n",
      "Epoch 358/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4973 - g_loss: 1.6158\n",
      "Epoch 359/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4979 - g_loss: 1.6143\n",
      "Epoch 360/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4980 - g_loss: 1.6222\n",
      "Epoch 361/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4935 - g_loss: 1.6230\n",
      "Epoch 362/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4978 - g_loss: 1.6331\n",
      "Epoch 363/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4929 - g_loss: 1.6421\n",
      "Epoch 364/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4968 - g_loss: 1.6325\n",
      "Epoch 365/450\n",
      "1875/1875 [==============================] - 15s 8ms/step - d_loss: 0.4949 - g_loss: 1.6359\n",
      "Epoch 366/450\n",
      " 960/1875 [==============>...............] - ETA: 7s - d_loss: 0.4921 - g_loss: 1.6424"
     ]
    }
   ],
   "source": [
    "gan.fit(train_dataset, epochs=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  1254400   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr multiple                  819200    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr multiple                  204800    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr multiple                  1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  50176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = discriminator(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.3145607]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f66dbb78890>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ganesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../gan/model/generator/assets\n"
     ]
    }
   ],
   "source": [
    "generator.save(Path(\"..\") / \"gan\" / \"model\" / \"generator\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f6570662990>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ../gan/model/discriminator/assets\n"
     ]
    }
   ],
   "source": [
    "discriminator.save(Path(\"..\") / \"gan\" / \"model\" / \"discriminator\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "generator = keras.models.load_model(Path(\"..\") / \"gan\" / \"model\" / \"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff94899cf10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
